import time
import uvicorn
import redis
import json
import hashlib
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from agent_rag import app as rag_agent

# 1. è¿æ¥ Redis (è¿™å°±å¥½æ¯”é›‡äº†ä¸€ä¸ªè®°æ€§å¾ˆå¥½çš„ç§˜ä¹¦)
# host='localhost' è¡¨ç¤º Redis å°±åœ¨æœ¬æœº
# port=6379 æ˜¯ Redis çš„é»˜è®¤ç«¯å£
redis_client = redis.Redis(host='localhost', port=6380, db=0, decode_responses=True)

app = FastAPI(title="Cached RAG Service")


class ChatRequest(BaseModel):
    question: str


class ChatResponse(BaseModel):
    answer: str
    latency: float
    source: str  # æ–°å¢å­—æ®µï¼šå‘Šè¯‰ä½ ç­”æ¡ˆæ˜¯ "Model" ç®—çš„ï¼Œè¿˜æ˜¯ "Cache" æŸ¥çš„


def get_cache_key(text):
    """æŠŠé—®é¢˜å˜æˆä¸€ä¸ªå”¯ä¸€çš„æŒ‡çº¹(MD5)ï¼Œæ–¹ä¾¿å­˜å‚¨"""
    return hashlib.md5(text.encode()).hexdigest()


@app.post("/chat", response_model=ChatResponse)
async def chat_endpoint(request: ChatRequest):
    start_time = time.time()

    # --- æ ¸å¿ƒ Infra é€»è¾‘ï¼šå…ˆæŸ¥ç¼“å­˜ ---
    cache_key = get_cache_key(request.question)
    cached_result = redis_client.get(cache_key)

    if cached_result:
        # å‘½ä¸­ç¼“å­˜ï¼ç›´æ¥è¿”å›ï¼Œä¸æ‰“æ‰°æ˜¾å¡
        end_time = time.time()
        print(f"âš¡ å‘½ä¸­ç¼“å­˜: {request.question[:10]}...")
        return {
            "answer": cached_result,
            "latency": round(end_time - start_time, 3),
            "source": "Redis Cache âš¡"  # æ ‡è®°æ¥æº
        }

    # --- ç¼“å­˜æ²¡å‘½ä¸­ï¼Œåªèƒ½è¾›è‹¦æ˜¾å¡äº† ---
    try:
        print(f"ğŸ¢ æ˜¾å¡è®¡ç®—ä¸­: {request.question[:10]}...")
        inputs = {"question": request.question, "retry_count": 0}
        result = rag_agent.invoke(inputs)
        final_answer = result.get("generation", "Error")

        # --- ç®—å®Œåï¼Œé©¬ä¸Šè®°åˆ°å°æœ¬æœ¬(Redis)ä¸Š ---
        # ex=3600 è¡¨ç¤ºè¿™æ¡è®°å½•åªå­˜ 1 å°æ—¶ï¼Œè¿‡æœŸè‡ªåŠ¨åˆ é™¤
        redis_client.set(cache_key, final_answer, ex=3600)

        end_time = time.time()
        return {
            "answer": final_answer,
            "latency": round(end_time - start_time, 3),
            "source": "LLM Inference ğŸ¢"
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)